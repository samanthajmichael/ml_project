{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbGh0YVvOxEmQBxrlhh27V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanthajmichael/ml_project/blob/main/notebooks/MTCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## this one took about 5 mins to run\n",
        "# %%capture\n",
        "# !pip install facenet-pytorch"
      ],
      "metadata": {
        "id": "qlCSDjxCyBSW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change Runtime to GPU"
      ],
      "metadata": {
        "id": "xow88ntx3epa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "7ET0c6Uiwyid"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eBJla2PTv0GL"
      },
      "outputs": [],
      "source": [
        "class MovieFrameAnalyzer:\n",
        "    def __init__(self, face_confidence=0.9, scene_threshold=30.0):\n",
        "        \"\"\"\n",
        "        Initialize detectors for both faces and scene cuts\n",
        "\n",
        "        Args:\n",
        "            face_confidence (float): Confidence threshold for face detection\n",
        "            scene_threshold (float): Threshold for scene cut detection\n",
        "        \"\"\"\n",
        "        # Initialize MTCNN for face detection\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.face_detector = MTCNN(\n",
        "            keep_all=True,\n",
        "            device=self.device,\n",
        "            min_face_size=20,\n",
        "            thresholds=[0.6, 0.7, face_confidence]\n",
        "        )\n",
        "\n",
        "        self.scene_threshold = scene_threshold\n",
        "\n",
        "    def detect_faces(self, image):\n",
        "        \"\"\"\n",
        "        Detect faces in an image\n",
        "        \"\"\"\n",
        "        boxes, probs = self.face_detector.detect(image)\n",
        "\n",
        "        return {\n",
        "            'has_faces': boxes is not None,\n",
        "            'num_faces': len(boxes) if boxes is not None else 0,\n",
        "            'face_confidence': max(probs) if probs is not None and len(probs) > 0 else 0,\n",
        "            'face_locations': boxes.tolist() if boxes is not None else []\n",
        "        }\n",
        "\n",
        "    def detect_scene_cut(self, frame1, frame2):\n",
        "        \"\"\"\n",
        "        Detect if there's a scene cut between two frames\n",
        "\n",
        "        Args:\n",
        "            frame1: Previous frame\n",
        "            frame2: Current frame\n",
        "\n",
        "        Returns:\n",
        "            dict: Scene cut analysis\n",
        "        \"\"\"\n",
        "        # Convert frames to grayscale\n",
        "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)\n",
        "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Calculate frame difference\n",
        "        diff = cv2.absdiff(gray1, gray2)\n",
        "        mean_diff = np.mean(diff)\n",
        "\n",
        "        # Calculate histogram difference\n",
        "        hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])\n",
        "        hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])\n",
        "        hist_diff = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
        "\n",
        "        # Detect motion\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
        "        )\n",
        "        motion_magnitude = np.mean(np.abs(flow))\n",
        "\n",
        "        # Analyze color changes\n",
        "        color_diff = np.mean(cv2.absdiff(frame1, frame2))\n",
        "\n",
        "        # Determine if it's a scene cut\n",
        "        is_cut = (mean_diff > self.scene_threshold or\n",
        "                 hist_diff < 0.5 or\n",
        "                 color_diff > self.scene_threshold)\n",
        "\n",
        "        return {\n",
        "            'is_scene_cut': is_cut,\n",
        "            'confidence': min(1.0, max(mean_diff / self.scene_threshold,\n",
        "                                     1 - hist_diff,\n",
        "                                     color_diff / self.scene_threshold)),\n",
        "            'transition_type': self.determine_transition_type(mean_diff, hist_diff, motion_magnitude),\n",
        "            'motion_magnitude': float(motion_magnitude),\n",
        "            'color_difference': float(color_diff),\n",
        "            'histogram_correlation': float(hist_diff)\n",
        "        }\n",
        "\n",
        "    def determine_transition_type(self, diff, hist_diff, motion):\n",
        "        \"\"\"\n",
        "        Determine the type of transition between frames\n",
        "        \"\"\"\n",
        "        if motion > 5.0:\n",
        "            return 'motion_blur'\n",
        "        elif diff > self.scene_threshold * 1.5:\n",
        "            return 'hard_cut'\n",
        "        elif hist_diff < 0.3:\n",
        "            return 'fade'\n",
        "        elif diff > self.scene_threshold:\n",
        "            return 'dissolve'\n",
        "        else:\n",
        "            return 'continuous'\n",
        "\n",
        "    def analyze_composition(self, frame):\n",
        "        \"\"\"\n",
        "        Analyze frame composition\n",
        "        \"\"\"\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Detect edges\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "        # Calculate compositional metrics\n",
        "        height, width = gray.shape\n",
        "        center_weight = np.mean(gray[height//3:2*height//3, width//3:2*width//3])\n",
        "        edge_density = np.mean(edges > 0)\n",
        "\n",
        "        return {\n",
        "            'composition_style': self.get_composition_type(center_weight, edge_density),\n",
        "            'edge_density': float(edge_density),\n",
        "            'center_weight': float(center_weight)\n",
        "        }\n",
        "\n",
        "    def get_composition_type(self, center_weight, edge_density):\n",
        "        \"\"\"\n",
        "        Determine composition type based on metrics\n",
        "        \"\"\"\n",
        "        if edge_density > 0.3:\n",
        "            if center_weight > 128:\n",
        "                return 'centered_detailed'\n",
        "            else:\n",
        "                return 'rule_of_thirds'\n",
        "        else:\n",
        "            if center_weight > 128:\n",
        "                return 'minimal_centered'\n",
        "            else:\n",
        "                return 'minimal_balanced'\n",
        "\n",
        "    def process_frames(self, frames_dir, output_file='frame_analysis.csv'):\n",
        "        \"\"\"\n",
        "        Process all frames in directory\n",
        "        \"\"\"\n",
        "        frames_path = Path(frames_dir)\n",
        "        results = []\n",
        "        previous_frame = None\n",
        "\n",
        "        for img_path in tqdm(sorted(frames_path.glob('*.jpg'))):\n",
        "            # Load current frame\n",
        "            current_frame = np.array(Image.open(img_path))\n",
        "\n",
        "            # Analyze faces\n",
        "            face_data = self.detect_faces(Image.fromarray(current_frame))\n",
        "\n",
        "            # Analyze scene cut if we have a previous frame\n",
        "            if previous_frame is not None:\n",
        "                scene_data = self.detect_scene_cut(previous_frame, current_frame)\n",
        "            else:\n",
        "                scene_data = {\n",
        "                    'is_scene_cut': False,\n",
        "                    'confidence': 0.0,\n",
        "                    'transition_type': 'start',\n",
        "                    'motion_magnitude': 0.0,\n",
        "                    'color_difference': 0.0,\n",
        "                    'histogram_correlation': 1.0\n",
        "                }\n",
        "\n",
        "            # Analyze composition\n",
        "            comp_data = self.analyze_composition(current_frame)\n",
        "\n",
        "            # Combine results\n",
        "            frame_data = {\n",
        "                'filename': img_path.name,\n",
        "                **face_data,\n",
        "                **scene_data,\n",
        "                **comp_data\n",
        "            }\n",
        "\n",
        "            results.append(frame_data)\n",
        "            previous_frame = current_frame\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(output_file, index=False)\n",
        "\n",
        "        # Print summary\n",
        "        print(\"\\nAnalysis Summary:\")\n",
        "        print(f\"Total frames processed: {len(df)}\")\n",
        "        print(f\"Frames with faces: {df['has_faces'].sum()}\")\n",
        "        print(f\"Scene cuts detected: {df['is_scene_cut'].sum()}\")\n",
        "        print(\"\\nTransition types:\")\n",
        "        print(df['transition_type'].value_counts())\n",
        "        print(\"\\nComposition styles:\")\n",
        "        print(df['composition_style'].value_counts())\n",
        "\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define paths\n",
        "DRIVE_FOLDER = \"/content/drive/MyDrive/ML Project/scene_cuts\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ML Project/labeled_data\"\n",
        "\n",
        "def ensure_dir_exists(directory):\n",
        "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    print(f\"Directory ready at: {directory}\")\n",
        "\n",
        "def save_dataframe(df, filename=\"scene_analysis.csv\"):\n",
        "    \"\"\"\n",
        "    Save DataFrame to Google Drive\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame to save\n",
        "        filename (str): Name of the output file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure output directory exists\n",
        "        ensure_dir_exists(OUTPUT_DIR)\n",
        "\n",
        "        # Create full output path\n",
        "        output_path = Path(OUTPUT_DIR) / filename\n",
        "\n",
        "        # Save DataFrame to CSV\n",
        "        df.to_csv(output_path, index=False)\n",
        "        print(f\"Data saved successfully to: {output_path}\")\n",
        "\n",
        "        # Print first few rows as verification\n",
        "        print(\"\\nFirst few rows of saved data:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Print file size\n",
        "        file_size = output_path.stat().st_size / (1024 * 1024)  # Convert to MB\n",
        "        print(f\"\\nFile size: {file_size:.2f} MB\")\n",
        "\n",
        "        # List contents of output directory\n",
        "        print(\"\\nContents of output directory:\")\n",
        "        for item in os.listdir(OUTPUT_DIR):\n",
        "            item_path = Path(OUTPUT_DIR) / item\n",
        "            if item_path.is_file():\n",
        "                size = item_path.stat().st_size / (1024 * 1024)  # Convert to MB\n",
        "                print(f\"{item} ({size:.2f} MB)\")\n",
        "            else:\n",
        "                print(f\"{item}/ (directory)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving file: {str(e)}\")\n",
        "        print(f\"Attempted to save to: {OUTPUT_DIR}\")\n",
        "\n",
        "        # Print directory existence check\n",
        "        print(f\"\\nDirectory check:\")\n",
        "        print(f\"Output directory exists: {os.path.exists(OUTPUT_DIR)}\")\n",
        "        print(f\"Parent directory exists: {os.path.exists(os.path.dirname(OUTPUT_DIR))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XvIEsMXxcCO",
        "outputId": "a8ca2f15-bb70-47bd-c153-2ccf201d3205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    analyzer = MovieFrameAnalyzer()\n",
        "    df = analyzer.process_frames(DRIVE_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YdCoc1Aw41-",
        "outputId": "1e546ad4-90a9-423a-be86-85afddab0925"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 859/859 [13:54<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis Summary:\n",
            "Total frames processed: 859\n",
            "Frames with faces: 619\n",
            "Scene cuts detected: 739\n",
            "\n",
            "Transition types:\n",
            "transition_type\n",
            "motion_blur    464\n",
            "dissolve       231\n",
            "continuous     117\n",
            "hard_cut        36\n",
            "fade            10\n",
            "start            1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Composition styles:\n",
            "composition_style\n",
            "minimal_balanced    858\n",
            "minimal_centered      1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}